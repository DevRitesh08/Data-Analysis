{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Importing pandas library"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from numpy.ma.core import squeeze\n",
    "from unicodedata import category"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Opening a local csv file"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df = pd.read_csv('IPL Matches 2008-2020.csv')\n",
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Opening a csv file from an URL"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/cs109/2014_data/master/countries.csv\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:66.0) Gecko/20100101 Firefox/66.0\"}\n",
    "req = requests.get(url, headers=headers)\n",
    "data = StringIO(req.text)\n",
    "\n",
    "pd.read_csv(data)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Sep Parameter"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "pd.read_csv('movie_titles_metadata.tsv',sep='\\t')",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# since we had no column names in the tsv file so we can also provide them like this :\n",
    "pd.read_csv('movie_titles_metadata.tsv',sep='\\t' , names=['movie_id','title','year','IMDB Rating','Votes','Genres'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Index_col parameter"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pd.read_csv('aug_train.csv')\n",
    "# here the index column is not useful , its better to make enrollee_id our new index ."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pd.read_csv('aug_train.csv',index_col='enrollee_id')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Header parameter"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pd.read_csv('test.csv')\n",
    "# here in this csv the column names is the first row but it was written with 0 (0,sth,sth...) so it is not considered as header by pandas , we can use header parameter ."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pd.read_csv('test.csv',header=1)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. use_cols parameter"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pd.read_csv('aug_train.csv',usecols=['enrollee_id','gender','education_level'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. Skiprows/nrows Parameter"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pd.read_csv('aug_train.csv',skiprows=2)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pd.read_csv('aug_train.csv',nrows=100)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`nrows is an important parameterm since it only import the specified number of rows only .`"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 9. Encoding parameter"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# pd.read_csv('zomato.csv')\n",
    "# UnicodeDecodeError\n",
    "# here the encoding of the file is not utf-8 so we have to use encoding parameter .\n",
    "pd.read_csv('zomato.csv', encoding='latin-1')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 10. Skip bad lines"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# pd.read_csv('bad_lines.csv')\n",
    "# Error due to bad lines (ParserError ) : Expected 5 fields in line 10, saw 6\n",
    "pd.read_csv('bad_lines.csv',on_bad_lines='skip')\n",
    "# we can also use on_bad_lines='warn' to get a warning instead of error ."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 11. dtypes parameter"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "a = pd.read_csv('aug_train.csv')\n",
    "a.info()\n",
    "# here we can see that the column 'city_development_index' is float64, but it should be float32 to save memory and"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "pd.read_csv('aug_train.csv',dtype={'gender': 'category' ,'education_level': 'category' , 'training_hours': np.int32 , 'city_development_index' : np.float32}).info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 12. Handling Dates"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pd.read_csv('IPL Matches 2008-2020.csv',parse_dates=['date']).info()\n",
    "# here we can see that the date column is now in datetime64[ns] format ."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def rename(name):\n",
    "    if name == \"Royal Challengers Bangalore\":\n",
    "        return \"RCB\"\n",
    "    else:\n",
    "        return name"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "rename(\"Royal Challengers Bangalore\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 13. Convertors"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# convertors is a dictionary of functions for converting values in certain columns . The keys can either be integers or column labels .\n",
    "# here we will rename the team1 column values using the above function .\n",
    "pd.read_csv('IPL Matches 2008-2020.csv',converters={'team1':rename})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 14. na_values parameter"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pd.read_csv('aug_train.csv',na_values=['No relevent experience' , 'no_enrollment','<1'])\n",
    "# here all the above values will be considered as NaN ."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 15. Loading a huge dataset in chunks"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "pd.read_csv('aug_train.csv').shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DFs = pd.read_csv('aug_train.csv', chunksize=5000)\n",
    "# here in order to save memory we can load the dataset in chunks of 5000 rows each ."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# DFs is an iterable object , we can iterate over it to get the chunks .\n",
    "for chunks in DFs:\n",
    "    print(chunks.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exel Files\n",
    "- to read exel files we use pd.read_exel() function .\n",
    "- it also has the same parameters as pd.read_csv() function .\n",
    "- we can also specify the sheet name using sheet_name parameter .\n",
    "- to read all the sheets we can use sheet_name=None"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## txt Files\n",
    "- to read txt files we can use pd.read_csv() function with sep parameter .\n",
    "- for example if the txt file is space separated we can use sep='\\s+'\n",
    "- it also has the same parameters as pd.read_csv() function ."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pd.read_csv('batter.txt',sep='\\t' )",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Json Files\n",
    "- to read json files we use pd.read_json() function .\n",
    "- it also has the same parameters as pd.read_csv() function .\n",
    "- can also read json from a url example :\n",
    "    - pd.read_json('https://api.github.com/users')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Sql Files\n",
    "- to read sql files we use pd.read_sql() function .\n",
    "- it also has the same parameters as pd.read_csv() function ."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install mysql-connector-python",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import mysql.connector\n",
    "conn = mysql.connector.connect(\n",
    "    host = \"localhost\",user = \"root\",password = \"11649872@MySQL\",database = \"world\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pd.read_sql_query(\"SELECT * FROM city\",conn)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# using sqlalchemy\n",
    "!pip install sqlalchemy"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# not working !!!!!!!!!\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(\"mysql+mysqlconnector://root:11649872@MySQL@localhost/world\", echo=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# pd.read_sql_query(\"SELECT * FROM city\",engine)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
